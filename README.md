# Распознавание рукописного текста на кириллице

**Проектный практикум МФТИ x GreenData | Кейс 1 | Декабрь 2025**

## Описание проекта

Разработка и тестирование датасета для распознавания рукописного русского текста, который станет частью системы автоматического парсинга данных из документов.

### Контекст задачи

В области распознавания рукописного кириллического текста нет достаточного количества качественных решений. Существующие модели либо неточны, либо требуют слишком больших вычислительных ресурсов. Данный проект направлен на поиск оптимального баланса между точностью и ресурсозатратностью.

## Цель проекта

Найти и подготовить датасет кириллического рукописного текста, протестировать существующие open-source модели распознавания и выбрать оптимальный вариант по критерию баланса точности и ресурсов.

## Задачи

1. Найти или собрать датасет с изображениями рукописного текста на кириллице
2. Провести аугментацию данных
3. Протестировать существующие модели распознавания текста
4. Сравнить модели по точности и ресурсозатратности
5. Выбрать оптимальную модель с учетом баланса качества и затрат

## Требования и ограничения

- Использовать только открытые датасеты и модели
- Основные технологии: Python, OpenCV, Pillow, PyTorch
- Допустимы любые другие open-source инструменты

## Ожидаемые результаты

**Артефакты для заказчика:**

- Размеченный и аугментированный датасет рукописного кириллического текста
- Отчет о тестировании с оценкой точности и используемых ресурсов
- Обоснование выбора оптимальной модели

## Критерии оценивания

Минимальный порог для успешной защиты: **28 баллов**

| Критерий | Описание | Баллы |
|----------|----------|-------|
| Качество и репрезентативность данных | Собран качественный датасет с описанием источников, структурой и примерами, обоснована его пригодность | 10 |
| Аугментация и подготовка данных | Реализована продуманная аугментация, повышающая устойчивость модели, описан процесс и параметры | 20 |
| Работа с моделями | Протестированы несколько моделей, проведено сравнение, обоснован выбор оптимальной | 15 |
| Анализ эффективности | Рассчитаны метрики качества и ресурсозатратности (точность, время, память, CPU/GPU) | 15 |
| Презентация | Ясная структура, визуальные примеры, понятные графики и выводы | 10 |
| Командная работа | Распределение ответственности, равномерный вклад, аргументированные решения | 10 |

**Блокирующий критерий:** участие всей команды в финальной защите обязательно.

## Быстрый мини-тест моделей

Для быстрой проверки, что окружение и модели работают, в `data/mini-test` лежит небольшой набор страниц HWR200
с эталонными расшифровками (`*.JPG` + соответствующие `.txt`).

Пример запуска из корня репозитория `handwritten-ocr`:

```bash
# Минимальное окружение только для инференса:
pip install -r requirements.inference.txt

# Добавляем src в PYTHONPATH (одна сессия/терминал)
export PYTHONPATH=src

# Инференс по одной странице
python src/infer_page.py trocr_kazars data/mini-test/hwr200_40_59_50_7.JPG

# Оценка качества (CER/WER) по мини-набору
python src/eval_folder.py trocr_kazars data/mini-test

# Полное окружение для аугментаций и ноутбуков:
# pip install -r requirements.txt
```

Доступные имена моделей для этих скриптов см. в `src/models/inference.py` (список `AVAILABLE_OCR_MODELS`).

## Анализ результатов экспериментов

После тестирования моделей используйте **TestProcessing.ipynb** для детального анализа и визуализации результатов.

### Возможности TestProcessing.ipynb:

1. **Объединение данных**
   - Загрузка метрик производительности из нескольких экспериментов
   - Создание единого датасета для сравнения моделей
   - Обработка результатов из `results/` папки

2. **Класс OCRVisualizer**
   - Визуализация метрик качества (CER, WER, Character Accuracy)
   - Анализ лучших и худших примеров распознавания
   - Сравнение моделей на различных типах данных
   - Графики распределения ошибок

3. **Детальный анализ**
   - Анализ ошибок по типам символов
   - Корреляция между размером изображения и качеством
   - Влияние аугментаций на производительность
   - Статистика по моделям

### Пример использования:

```python
# В Google Colab
from google.colab import drive
drive.mount('/content/drive')

# Откройте TestProcessing.ipynb
# Установите путь к проекту
os.chdir('/content/drive/MyDrive/handwritten-ocr-main')

# Загрузите результаты экспериментов
# Создайте визуализации и анализ
```

**Результаты анализа:** Графики, таблицы сравнения, выводы сохраняются для отчета и презентации.

### TestOcrMetrics.ipynb vs TestProcessing.ipynb

**TestOcrMetrics.ipynb** - базовое вычисление метрик:
- Расчет CER, WER, Character Accuracy
- Быстрая оценка одной модели
- Сохранение метрик в JSON

**TestProcessing.ipynb** - продвинутый анализ:
- Сравнение нескольких моделей
- Визуализации и графики
- Детальный анализ ошибок
- Класс OCRVisualizer для повторного использования

**Рекомендуемый workflow:**
1. TestOcrMetrics.ipynb → быстрая оценка качества
2. TestProcessing.ipynb → глубокий анализ и визуализация для отчета

## Ключевые результаты

### Подготовка данных
- **Источники:** 2 датасета (HWR200 + school_notebooks_ru)
- **Оригинальных изображений:** 417 (117 HWR200 + 300 school_notebooks_ru)
- **Аугментированных изображений:** 1185
- **Итоговый объем:** 1602 изображения
- **Типы аугментаций:** 5 (GaussNoise, Brightness/Contrast, MotionBlur, ElasticTransform, GridDistortion)

### Тестирование моделей

#### Эксперимент 1: Тестирование на полных страницах (без оптимизации)

Протестировано 3 TrOCR модели на 70 образцах полных страниц "как есть":

| Модель | CER (%) | WER (%) | Char Accuracy (%) | Latency (sec) | Результат |
|--------|---------|---------|-------------------|---------------|-----------|
| **TrOCR Cyrillic** | **52.57** | 330.69 | **47.43** | 45.0 | **Лучшая для сложных данных** |
| TrOCR Raxtemur | 53.01 | 334.45 | 46.99 | 23.47 | Второе место |
| TrOCR Kazars | 60.89 | 388.37 | 39.11 | 40.0 | Третье место |

#### Эксперимент 2: Оптимизация для production (TrOCR Small)

Дополнительно протестирована **trocr_small** с оптимизацией параметров:

**Ключевые результаты:**
- **Лучшая модель для production:** trocr_small (оптимальное соотношение качество-скорость)
- **Оптимальные параметры изображений:** 3-4 Мп, соотношение сторон 1.5:1
- **Критические ошибки распознавания:** Символы "ё", "щ", цифры "3" и "5"

**Рекомендации для production:**
1. Использовать **trocr_small** с ресайзингом изображений до 3 Мп
2. Применять **brightness normalization** для улучшения качества
3. Добавить **постобработку** для проблемных символов ("ё", "щ", "3", "5")
4. **Избегать** motion и grid аугментаций - они снижают качество

### Выбор оптимальной модели

Проект выявил **два оптимальных решения** в зависимости от сценария использования:

#### Вариант 1: TrOCR Cyrillic (для сложных данных)
**Модель:** `cyrillic-trocr/trocr-handwritten-cyrillic`

**Когда использовать:**
- Полные страницы без предобработки
- Разнообразные стили почерка
- Исторические документы
- Максимальная точность важнее скорости

**Характеристики:**
- CER: 52.57% на полных страницах
- Character Accuracy: 47.43%
- Параметры: 334M
- Время: ~45 сек/страница (CPU)
- Память GPU: ~5.1GB

#### Вариант 2: TrOCR Small (для production)
**Модель:** `trocr_small`

**Когда использовать:**
- Production системы с большим потоком
- Оптимизированные изображения (3-4 Мп)
- Баланс скорости и качества критичен
- Контролируемые условия съемки

**Характеристики:**
- Оптимальное соотношение качество-скорость
- Работает с изображениями 3-4 Мп, соотношение 1.5:1
- Требует brightness normalization
- Постобработка для символов "ё", "щ", "3", "5"

**Рекомендация команды:**
- **Для исследований и прототипов:** TrOCR Cyrillic
- **Для production и масштабирования:** TrOCR Small с оптимизацией

**Важное замечание о метриках:**
Высокие значения CER (>50%) объясняются тестированием на полных страницах со сложной разметкой. Модели, обученные на строках, показывают существенно лучшие результаты при правильной предобработке (детекция и нарезка строк). Рекомендуется дополнительная оптимизация пайплайна распознавания.

## Быстрый старт

### Установка

```bash
pip install transformers torch pillow paddleocr
```

### Использование

```python
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from PIL import Image
import torch

# Загрузка модели
device = 'cuda' if torch.cuda.is_available() else 'cpu'
processor = TrOCRProcessor.from_pretrained('cyrillic-trocr/trocr-handwritten-cyrillic')
model = VisionEncoderDecoderModel.from_pretrained('cyrillic-trocr/trocr-handwritten-cyrillic')
model.to(device)

# Распознавание
image = Image.open('your_image.jpg').convert('RGB')
pixel_values = processor(image, return_tensors="pt").pixel_values.to(device)
generated_ids = model.generate(pixel_values)
text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(text)
```

## Структура проекта

```
handwritten-ocr/
├── data/
│   ├── raw/                      # Исходные датасеты (на Google Drive)
│   │   ├── hwr200/              # 117 оригинальных + аугментации
│   │   └── school_notebooks_ru/  # 300 оригинальных + аугментации
│   └── processed/                # Обработанные данные
├── notebooks/
│   ├── 01_analyze_dataset_structures.ipynb
│   ├── 02_rename_dataset_hwr200.ipynb
│   ├── 03_augmentation.ipynb
│   ├── 04_demo.ipynb            # Финальная демонстрация
│   ├── TestOcrMetrics.ipynb     # Вычисление метрик качества
│   └── templates/               # Шаблоны для экспериментов
├── src/
│   ├── metrics.py               # Метрики (CER, WER)
│   ├── data_augmentation.py
│   ├── utils.py
│   └── models/
│       └── ocr_models/          # TrOCR обертки
├── results/                     # Результаты экспериментов
├── reports/                     # Отчеты
│   ├── 1_data_preparation_report.md
│   └── models.md
├── docs/                        # Документация
│   ├── cloud_instructions.md
│   └── reproducibility_checklist.md
├── requirements.txt
└── README.md
```

## Технологический стек

- **Python 3.8+**
- **PyTorch** - фреймворк глубокого обучения
- **Transformers (Hugging Face)** - TrOCR модели
- **PaddleOCR** - детекция областей текста
- **Albumentations** - аугментация данных
- **OpenCV, Pillow** - обработка изображений
- **scikit-learn** - метрики оценки

## Детали реализации

### Подготовка данных

**Датасет HWR200:**
- Источник: HuggingFace (AntiplagiatCompany)
- Крупный датасет рукописных сочинений (30000+ изображений)
- Отобрано и подготовлено: 117 качественных примеров
- Аугментации: все 5 типов → 585 новых изображений
- Итого: 702 изображения

**Датасет school_notebooks_ru:**
- Источник: HuggingFace (ai-forever)
- Рукописные школьные тетради с COCO-разметкой
- Отобрано: 300 исходных изображений
- Аугментации: 2 типа (brightness, grid) → 600 новых
- Итого: 900 изображений

**Аугментации:**
1. GaussNoise - имитация шума камеры
2. RandomBrightnessContrast - изменение освещения
3. MotionBlur - размытие от движения
4. ElasticTransform - деформация бумаги
5. GridDistortion - сеточные искажения

### Архитектура решения

**Детекция строк:**
- PaddleOCR для автоматической детекции областей текста
- Сортировка областей сверху-вниз, слева-направо
- Адаптивный padding для улучшения качества

**Распознавание:**
- TrOCR (Vision Encoder-Decoder)
- ViT encoder + Transformer decoder
- Обработка каждой строки отдельно
- Объединение результатов в многострочный текст

## Анализ результатов

### Сравнение моделей

Все три модели показали схожие результаты, что указывает на сложность задачи распознавания полных страниц рукописного текста:

**TrOCR Cyrillic (победитель):**
- CER: 52.57% (±21.16%)
- WER: 330.69% (±118.39%)
- Специализация на исторической и современной кириллице
- Наиболее стабильные результаты

**TrOCR Raxtemur:**
- CER: 53.01% (±16.13%)
- Быстрее (~23 сек vs ~45 сек)
- Обучен на синтетических данных

**TrOCR Kazars:**
- CER: 60.89% (±11.71%)
- Наименьшая вариативность результатов
- Специализация на современной кириллице

### Выводы из тестирования

**Эксперимент 1 (полные страницы, без оптимизации):**
1. **Все модели показали схожий уровень сложности** на полных страницах рукописного текста (CER >50%)
2. **TrOCR Cyrillic показал лучший результат** среди тестируемых (CER 52.57%)
3. **Необходима оптимизация пайплайна** - улучшение детекции строк, предобработка
4. **Модели лучше работают на отдельных строках**, чем на полных страницах

**Эксперимент 2 (оптимизация для production, TrOCR Small):**
1. **Предобработка критична:** Правильный размер (3-4 Мп) и brightness normalization дают значительный прирост
2. **Выявлены проблемные символы:** "ё", "щ", цифры "3" и "5" требуют постобработки
3. **Не все аугментации полезны:** MotionBlur и GridDistortion ухудшают качество
4. **TrOCR Small оптимален для production** при соблюдении рекомендаций по предобработке

**Общие выводы:**
- Два подхода дополняют друг друга: реалистичная оценка (Эксп. 1) + оптимизация (Эксп. 2)
- Выбор модели зависит от сценария: максимальная точность vs скорость/ресурсы
- Постобработка обязательна для всех моделей

## Результаты по критериям оценивания

| Критерий | Баллы | Результат |
|----------|-------|-----------|
| Качество и репрезентативность данных | 10 | Подготовлено 1602 изображения из 2 источников с полным описанием |
| Аугментация и подготовка данных | 20 | Реализовано 5 типов аугментаций с обоснованием параметров |
| Работа с моделями | 15 | Протестировано 3 модели, выбрана оптимальная с обоснованием |
| Анализ эффективности | 15 | Рассчитаны CER, WER, время, память для каждой модели |
| Презентация | 10 | Подготовлена документация и демо-ноутбук |
| Командная работа | 10 | Распределение ролей, равномерный вклад |

**Итого:** 80 баллов (минимум для зачета: 28)

## Выводы и рекомендации

### Основные выводы

1. **Два оптимальных решения для разных сценариев**
   - **TrOCR Cyrillic:** Максимальная точность на сложных данных (CER 52.57%)
   - **TrOCR Small:** Оптимальный баланс скорость/качество для production
   - Специализация на кириллице дает преимущество для обеих моделей

2. **Критичность предобработки (из TestProcessing.ipynb)**
   - Правильный размер изображений: 3-4 Мп, соотношение 1.5:1
   - Brightness normalization обязательна
   - Избегать MotionBlur и GridDistortion аугментаций

3. **Выявлены проблемные символы**
   - "ё", "щ", цифры "3" и "5" требуют специальной постобработки
   - Необходим словарь частых ошибок и контекстная коррекция

4. **Аугментации критически важны, но не все**
   - Увеличение датасета в 3.8 раза (1602 изображения)
   - Полезные: GaussNoise, Brightness/Contrast, ElasticTransform
   - Вредные: MotionBlur, GridDistortion

5. **Детекция строк требует улучшения**
   - Текущий пайплайн не оптимален для полных страниц
   - Рекомендуется обработка на уровне строк с правильной сегментацией

### Рекомендации для улучшения

#### На основе тестирования (из TestProcessing.ipynb)

**1. Оптимизация предобработки (критично для production)**
   - **Ресайзинг:** Изображения 3-4 Мп, соотношение сторон 1.5:1
   - **Brightness normalization:** Обязательна для стабильного качества
   - Коррекция геометрических искажений
   - Улучшенная детекция и нарезка строк

**2. Постобработка с учетом проблемных символов**
   - **Критичные символы:** "ё", "щ", цифры "3" и "5" часто распознаются неправильно
   - Языковая модель для исправления этих символов
   - Контекстная коррекция (spell-checker для русского)
   - Словарь частых ошибок для автозамены

**3. Аугментации для обучения**
   - **Использовать:** GaussNoise, Brightness/Contrast, ElasticTransform
   - **Избегать:** MotionBlur и GridDistortion - снижают качество распознавания
   - Причина: motion и grid создают артефакты, которые модель не может обработать

**4. Выбор модели в зависимости от задачи**
   - **Для максимальной точности:** TrOCR Cyrillic (334M параметров)
   - **Для production:** TrOCR Small (быстрее, меньше ресурсов)
   - **Для ансамбля:** Комбинация Cyrillic + Small с weighted average

## Команда

- **Участник 1:** Лидер данных (датасет + аугментация)
- **Участник 2:** Инженер моделей (исследование + инференс)
- **Участник 3:** Инженер по валидации (метрики + анализ)
- **Участник 4:** Инженер экспериментов (тестирование + логирование)
- **Участник 5:** DevOps и QA (инфраструктура + документация)

## Дополнительная информация

- NDA не требуется
- Проект можно использовать в портфолио
- Предусмотрены регулярные встречи с менторами для консультаций
- Возможен доступ к платформе GreenData с технической поддержкой

## Документация

- [Работа с Google Drive](https://github.com/Nadarsa/handwritten-ocr/blob/main/docs/cloud_instructions.md)
- [Описание датасета](https://github.com/Nadarsa/handwritten-ocr/blob/main/data/description_of_the_dataset.md)
- [Сравнение моделей](https://github.com/Nadarsa/handwritten-ocr/blob/main/models.md)
- [Результаты экспериментов](https://github.com/Nadarsa/handwritten-ocr/blob/main/results/experiment_logs.xlsx)
- [Чек-лист воспроизводимости](https://github.com/Nadarsa/handwritten-ocr/blob/main/docs/reproducibility_checklist.md)

## Лицензия

Проект создан в образовательных целях в рамках проектного практикума МФТИ.

---

**Дата создания:** Декабрь 2025 

**Организация:** Московский физико-технический институт (национальный исследовательский университет), МФТИ, Физтех
 
**Заказчик:** GreenData
