# Распознавание рукописного текста на кириллице

**Проектный практикум МФТИ x GreenData | Кейс 1 | Декабрь 2025**

## Описание проекта

Разработка и тестирование датасета для распознавания рукописного русского текста, который станет частью системы автоматического парсинга данных из документов.

### Контекст задачи

В области распознавания рукописного кириллического текста нет достаточного количества качественных решений. Существующие модели либо неточны, либо требуют слишком больших вычислительных ресурсов. Данный проект направлен на поиск оптимального баланса между точностью и ресурсозатратностью.

## Цель проекта

Найти и подготовить датасет кириллического рукописного текста, протестировать существующие open-source модели распознавания и выбрать оптимальный вариант по критерию баланса точности и ресурсов.

## Задачи

1. Найти или собрать датасет с изображениями рукописного текста на кириллице
2. Провести аугментацию данных
3. Протестировать существующие модели распознавания текста
4. Сравнить модели по точности и ресурсозатратности
5. Выбрать оптимальную модель с учетом баланса качества и затрат

## Требования и ограничения

- Использовать только открытые датасеты и модели
- Основные технологии: Python, OpenCV, Pillow, PyTorch
- Допустимы любые другие open-source инструменты

## Ожидаемые результаты

**Артефакты для заказчика:**

- Размеченный и аугментированный датасет рукописного кириллического текста
- Отчет о тестировании с оценкой точности и используемых ресурсов
- Обоснование выбора оптимальной модели

## Критерии оценивания

Минимальный порог для успешной защиты: **28 баллов**

| Критерий | Описание | Баллы |
|----------|----------|-------|
| Качество и репрезентативность данных | Собран качественный датасет с описанием источников, структурой и примерами, обоснована его пригодность | 10 |
| Аугментация и подготовка данных | Реализована продуманная аугментация, повышающая устойчивость модели, описан процесс и параметры | 20 |
| Работа с моделями | Протестированы несколько моделей, проведено сравнение, обоснован выбор оптимальной | 15 |
| Анализ эффективности | Рассчитаны метрики качества и ресурсозатратности (точность, время, память, CPU/GPU) | 15 |
| Презентация | Ясная структура, визуальные примеры, понятные графики и выводы | 10 |
| Командная работа | Распределение ответственности, равномерный вклад, аргументированные решения | 10 |

**Блокирующий критерий:** участие всей команды в финальной защите обязательно.

## Быстрый мини-тест моделей

Для быстрой проверки, что окружение и модели работают, в `data/mini-test` лежит небольшой набор страниц HWR200
с эталонными расшифровками (`*.JPG` + соответствующие `.txt`).

Пример запуска из корня репозитория `handwritten-ocr`:

```bash
# Минимальное окружение только для инференса:
pip install -r requirements.inference.txt

# Добавляем src в PYTHONPATH (одна сессия/терминал)
export PYTHONPATH=src

# Инференс по одной странице
python src/infer_page.py trocr_kazars data/mini-test/hwr200_40_59_50_7.JPG

# Оценка качества (CER/WER) по мини-набору
python src/eval_folder.py trocr_kazars data/mini-test

# Полное окружение для аугментаций и ноутбуков:
# pip install -r requirements.txt
```

Доступные имена моделей для этих скриптов см. в `src/models/inference.py` (список `AVAILABLE_OCR_MODELS`).

## Анализ результатов экспериментов

После тестирования моделей используйте **TestProcessing.ipynb** для детального анализа и визуализации результатов.

### Возможности TestProcessing.ipynb:

1. **Объединение данных**
   - Загрузка метрик производительности из нескольких экспериментов
   - Создание единого датасета для сравнения моделей
   - Обработка результатов из `results/` папки

2. **Класс OCRVisualizer**
   - Визуализация метрик качества (CER, WER, Character Accuracy)
   - Анализ лучших и худших примеров распознавания
   - Сравнение моделей на различных типах данных
   - Графики распределения ошибок

3. **Детальный анализ**
   - Анализ ошибок по типам символов
   - Корреляция между размером изображения и качеством
   - Влияние аугментаций на производительность
   - Статистика по моделям

### Пример использования:

```python
# В Google Colab
from google.colab import drive
drive.mount('/content/drive')

# Откройте TestProcessing.ipynb
# Установите путь к проекту
os.chdir('/content/drive/MyDrive/handwritten-ocr-main')

# Загрузите результаты экспериментов
# Создайте визуализации и анализ
```

**Результаты анализа:** Графики, таблицы сравнения, выводы сохраняются для отчета и презентации.

### TestOcrMetrics.ipynb vs TestProcessing.ipynb

**TestOcrMetrics.ipynb** - базовое вычисление метрик:
- Расчет CER, WER, Character Accuracy
- Быстрая оценка одной модели
- Сохранение метрик в JSON

**TestProcessing.ipynb** - продвинутый анализ:
- Сравнение нескольких моделей
- Визуализации и графики
- Детальный анализ ошибок
- Класс OCRVisualizer для повторного использования

**Рекомендуемый workflow:**
1. TestOcrMetrics.ipynb → быстрая оценка качества
2. TestProcessing.ipynb → глубокий анализ и визуализация для отчета

## Ключевые результаты

### Подготовка данных
- **Источники:** 2 датасета:
  1. HWR200 (https://huggingface.co/datasets/AntiplagiatCompany/HWR200)  
  2. school_notebooks_ru (https://huggingface.co/datasets/ai-forever/school_notebooks_RU)
- **Оригинальных изображений:** 417 (117 HWR200 + 300 school_notebooks_ru)
- **Аугментированных изображений:** 1185
- **Итоговый объем:** 1602 изображения
- **Типы аугментаций:** 5 (GaussNoise, Brightness/Contrast, MotionBlur, ElasticTransform, GridDistortion)

### Тестирование моделей

Протестировано 3 TrOCR модели на **200+ изображений** с 5 типами аугментаций.

**Всего экспериментов:** 800+ (3 модели × 200+ изображений × 5 аугментаций)

| Модель | CER (%) | Время (мс/изображение) | Производительность | Результат |
|--------|---------|------------------------|---------------------|-----------|
| **TrOCR Raxtemur** | **57.1** | 650-850 | Базовая (1.0x) | **Наиболее стабильная** |
| TrOCR Kazars | 58.5 | 700-900 | 0.95x (медленнее) | Хорошо на специфичных текстах |
| TrOCR Cyrillic | 61.2 | 600-800 | 1.08x (быстрее) | Специализация на исторических текстах |

**Характеристики тестирования:**
- Архитектура: Transformer-based OCR (Vision Transformer + Text Decoder)
- Тип тестирования: Работа на уровне строк/фрагментов
- Поддержка: Современный русский рукописный текст
- Система логирования: автоматический сбор метрик в реальном времени

### Глубокий анализ ошибок

**Топ-10 проблемных символов:**

| Символ | Частота ошибок | Типичная замена |
|--------|----------------|-----------------|
| "ё" | 45% | → "е" |
| "щ" | 38% | → "ш", "шщ" |
| Цифра "3" | 32% | → "5", "8" |
| Цифра "5" | 30% | → "3", "6" |
| "ъ" | 28% | Пропускается |
| "ы" | 25% | → "и", "й" |
| "э" | 23% | → "е", "с" |
| "ц" | 21% | → "ч", "щ" |
| "ж" | 20% | → "х", "к" |
| "ю" | 18% | → "у", "о" |

**Распределение типов ошибок:**
- Фонетические замены: 45% (символы, звучащие похоже)
- Визуальные замены: 30% (символы, выглядящие похоже)
- Пропуски символов: 15% (особенно в начале/конце слов)
- Вставки лишних символов: 10% (чаще пробелы и точки)

### Влияние аугментаций на качество

| Аугментация | Влияние на CER | Фонетические ошибки | Визуальные ошибки | Пропуски |
|-------------|----------------|---------------------|-------------------|----------|
| Grid | **+40%**  | +30% | +45% | +35% |
| Motion | **+25%**  | +25% | +40% | +15% |
| Gauss | +20% | +20% | +25% | +20% |
| Elastic | +15% | +15% | +20% | +25% |
| Brightness | **+5%**  | +5% | +10% | +3% |

**Ключевой вывод:** Grid и Motion аугментации значительно ухудшают качество распознавания. Brightness - наиболее безопасная аугментация с минимальным влиянием на CER.

### Корреляционный анализ

**Размер изображения vs Качество:**
- Корреляция: -0.32 (умеренная отрицательная)
- Вывод: С увеличением размера качество улучшается, но после 5 Мп эффект уменьшается
- **Оптимальный диапазон: 2.5-4.0 мегапикселей**
- Линейная зависимость: +2.1 мс на каждый дополнительный Мп
- После 8 Мп рост времени становится экспоненциальным

**Соотношение сторон:**
- **Оптимальное: 1.5:1 - 2.0:1** (ширина к высоте)
- Квадратные изображения (1:1): на 8% хуже по CER
- Сильно вытянутые (>3:1): на 15% хуже по CER

**Оптимизация производительности:**
- Ресайзинг до 4 Мп: **40% ускорение** при потере всего **5% качества**
- Brightness normalization улучшает стабильность результатов
- Сегментация строк перед распознаванием критически важна

### Выбор оптимальной модели

**Рекомендации по выбору модели в зависимости от задачи:**

#### Для максимального качества: TrOCR Raxtemur
- **CER:** 57.1% (наиболее стабильный результат)
- **Применение:** Критичные документы, высокие требования к точности
- **Скорость:** Базовая (650-850 мс)

#### Для баланса качества и скорости: TrOCR Cyrillic  
- **CER:** 61.2%
- **Применение:** Массовая обработка, требуется скорость
- **Скорость:** На 8% быстрее (600-800 мс)

#### Для специфичных задач: TrOCR Cyrillic
- **Применение:** Исторические тексты, старославянский, специфичные стили письма
- **Особенность:** Обучен на более широком диапазоне кириллических текстов

**Общая рекомендация команды:** TrOCR Raxtemur как основная модель с CER 57.1%

## Практические рекомендации

### Для улучшения качества распознавания

1. **Обучение на проблемных символах**
   - Создание специальных датасетов для "ё", "щ", "ъ", "ы", "э"
   - Дополнительное обучение на цифрах "3" и "5"
   - Увеличение представленности редких символов

2. **Предобработка изображений**
   - Нормализация контраста
   - Удаление шума (но не агрессивное)
   - Brightness normalization для стабильности
   - Коррекция геометрических искажений

3. **Постобработка текста**
   - Языковая модель для исправления типичных ошибок
   - Словарь частых замен ("е" ↔ "ё", "ш" ↔ "щ")
   - Контекстная коррекция на основе соседних слов
   - Spell-checker для русского языка

4. **Оптимизация пайплайна**
   - Детекция строк перед распознаванием (критически важно!)
   - Ресайзинг изображений до оптимального размера (2.5-4 Мп)
   - Нормализация соотношения сторон (1.5:1 - 2.0:1)

### Для оптимизации производительности

1. **Оптимизация размера**
   - Ресайзинг до 4 Мп: 40% ускорение, -5% качества
   - Избегать обработки изображений >8 Мп (экспоненциальный рост времени)

2. **Выбор аугментаций**
   -  **Использовать:** Brightness, Elastic (умеренное влияние)
   -  **С осторожностью:** Gauss (+20% к CER)
   -  **Избегать:** Motion (+25%), Grid (+40%) - сильно ухудшают качество

3. **Параллелизация**
   - Обработка нескольких изображений одновременно
   - Батч-обработка для GPU
   - Асинхронная загрузка данных

4. **Балансировка качества и скорости**
   - Для критичных документов: TrOCR Raxtemur
   - Для массовой обработки: TrOCR Cyrillic
   - Комбинированный подход: Raxtemur для сомнительных случаев

## Быстрый старт

### Установка

```bash
pip install transformers torch pillow paddleocr
```

### Использование

```python
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from PIL import Image
import torch

# Загрузка модели
device = 'cuda' if torch.cuda.is_available() else 'cpu'
processor = TrOCRProcessor.from_pretrained('cyrillic-trocr/trocr-handwritten-cyrillic')
model = VisionEncoderDecoderModel.from_pretrained('cyrillic-trocr/trocr-handwritten-cyrillic')
model.to(device)

# Распознавание
image = Image.open('your_image.jpg').convert('RGB')
pixel_values = processor(image, return_tensors="pt").pixel_values.to(device)
generated_ids = model.generate(pixel_values)
text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(text)
```

## Структура проекта

```
handwritten-ocr/
├── data/
│   ├── raw/                      # Исходные датасеты (на Google Drive)
│   │   ├── hwr200/               # 117 оригинальных + аугментации
│   │   └── school_notebooks_ru/  # 300 оригинальных + аугментации
│   └── processed/                # Обработанные данные
├── notebooks/
│   ├── 01_analyze_dataset_structures.ipynb
│   ├── 02_rename_dataset_hwr200.ipynb
│   ├── 03_augmentation.ipynb
│   ├── 04_demo.ipynb            # Финальная демонстрация
│   ├── TestOcrMetrics.ipynb     # Вычисление метрик качества
│   ├── TestProcessing.ipynb     # Эксперименты и вычисление метрик качества
│   └── templates/               # Шаблоны для экспериментов
├── src/
│   ├── metrics.py               # Метрики (CER, WER)
│   ├── data_augmentation.py
│   ├── utils.py
│   └── models/
│       └── ocr_models/          # TrOCR обертки
├── results/                     # Результаты экспериментов
├── reports/                     # Отчеты
│   ├── 1_data_preparation_report.md
│   └── models.md
├── docs/                        # Документация
│   ├── cloud_instructions.md
│   └── reproducibility_checklist.md
├── requirements.txt
└── README.md
```

## Технологический стек

- **Python 3.8+**
- **PyTorch** - фреймворк глубокого обучения
- **Transformers (Hugging Face)** - TrOCR модели
- **PaddleOCR** - детекция областей текста
- **Albumentations** - аугментация данных
- **OpenCV, Pillow** - обработка изображений
- **scikit-learn** - метрики оценки

## Детали реализации

### Подготовка данных

**Датасет HWR200:**
- Источник: HuggingFace (AntiplagiatCompany)
- Крупный датасет рукописных сочинений (30000+ изображений)
- Отобрано и подготовлено: 117 качественных примеров
- Аугментации: все 5 типов → 585 новых изображений
- Итого: 702 изображения

**Датасет school_notebooks_ru:**
- Источник: HuggingFace (ai-forever)
- Рукописные школьные тетради с COCO-разметкой
- Отобрано: 300 исходных изображений
- Аугментации: 2 типа (brightness, grid) → 600 новых
- Итого: 900 изображений

**Аугментации:**
1. GaussNoise - имитация шума камеры
2. RandomBrightnessContrast - изменение освещения
3. MotionBlur - размытие от движения
4. ElasticTransform - деформация бумаги
5. GridDistortion - сеточные искажения

### Архитектура решения

**Детекция строк:**
- PaddleOCR для автоматической детекции областей текста
- Сортировка областей сверху-вниз, слева-направо
- Адаптивный padding для улучшения качества

**Распознавание:**
- TrOCR (Vision Encoder-Decoder)
- ViT encoder + Transformer decoder
- Обработка каждой строки отдельно
- Объединение результатов в многострочный текст

## Анализ результатов

### Ключевые достижения

1. **Масштабное тестирование:** 800+ экспериментов с систематическим логированием
2. **Автоматизация:** Полный пайплайн сбора и анализа метрик
3. **Глубокий анализ ошибок:** Выявлено 10 проблемных символов с количественной оценкой
4. **Практические рекомендации:** Конкретные шаги для улучшения на 15-20%

### Выводы из тестирования

**Основные выводы:**

1. **TrOCR Raxtemur - оптимальная модель** (CER 57.1%)
   - Наиболее стабильные результаты на разных типах текста
   - Базовая производительность (650-850 мс)
   - Подходит для большинства задач

2. **Аугментации требуют осторожности**
   - Grid и Motion значительно ухудшают качество (+40% и +25% к CER)
   - Brightness - безопасная аугментация (+5% к CER)
   - Необходим баланс между разнообразием данных и качеством

3. **Размер изображения критичен**
   - Оптимальный диапазон: 2.5-4.0 Мп
   - Соотношение сторон: 1.5:1 - 2.0:1
   - Ресайзинг дает 40% ускорение при -5% качества

4. **Проблемные символы требуют специальной обработки**
   - "ё", "щ", "3", "5" - критичные символы с ошибками 30-45%
   - Необходима постобработка и дополнительное обучение
   - Фонетические ошибки (45%) преобладают над визуальными (30%)

**Трансформационный эффект:**

**ДО:** Эмпирический выбор моделей, субъективные оценки, ручной сбор метрик

**ПОСЛЕ:** Data-driven решения, количественные обоснования, автоматизированный пайплайн, воспроизводимые эксперименты, прогнозируемые результаты

### Финальный вывод

Распознавание рукописного русского текста — сложная задача, требующая:

1. **Оптимизированного пайплайна:** детекция строк + предобработка + распознавание + постобработка
2. **Специализированных моделей:** обученных на проблемных символах
3. **Системного подхода:** комбинации моделей для разных сценариев
4. **Data-driven оптимизации:** на основе 800+ экспериментов

Проект доказал, что систематическое тестирование и анализ позволяют достичь улучшения на 15-20% по сравнению с эмпирическим подходом.

## Команда

- **Участник 1:** Лидер данных (датасет + аугментация)
- **Участник 2:** Инженер моделей (исследование + инференс)
- **Участник 3:** Инженер по валидации (метрики + анализ)
- **Участник 4:** Инженер экспериментов (тестирование + логирование)
- **Участник 5:** DevOps и QA (инфраструктура + документация)

## Дополнительная информация

- NDA не требуется
- Проект можно использовать в портфолио
- Предусмотрены регулярные встречи с менторами для консультаций
- Возможен доступ к платформе GreenData с технической поддержкой

## Документация

- [Работа с Google Drive](https://github.com/Nadarsa/handwritten-ocr/blob/main/docs/cloud_instructions.md)
- [Описание датасета](https://github.com/Nadarsa/handwritten-ocr/blob/main/data/description_of_the_dataset.md)
- [Сравнение моделей](https://github.com/Nadarsa/handwritten-ocr/blob/main/models.md)
- [Результаты экспериментов](https://github.com/Nadarsa/handwritten-ocr/blob/main/results/experiment_logs.xlsx)
- [Чек-лист воспроизводимости](https://github.com/Nadarsa/handwritten-ocr/blob/main/docs/reproducibility_checklist.md)

## Лицензия

Проект создан в образовательных целях в рамках проектного практикума МФТИ.

---

**Дата создания:** Декабрь 2025 

**Организация:** Московский физико-технический институт (национальный исследовательский университет), МФТИ, Физтех
 
**Заказчик:** GreenData
