# Отчет: Построение pipeline метрик и создание тестового набора данных

## 1. Цель работы

Разработка автоматизированного pipeline для оценки качества моделей распознавания рукописного текста на кириллице и обработка аугментированных данных из созданных папок для подачи на вход моделям.

## 2. Подготовка данных

### 2.1 Структура данных

Использованы два датасета:
- **HWR200**: 585 образцов с аннотациями в `.txt` файлах
- **School Notebooks**: 600 образцов с аннотациями в `CSV` (bbox-разметка)

### 2.2 Реализованный функционал

Класс `TestDataPreparer` обеспечивает:

**Автоматическое сопоставление изображений с аннотациями:**
- Поддержка множественных форматов изображений (jpg, jpeg, png)
- Удаление суффиксов аугментации (`_bright`, `_elastic`, `_grid` и др.)
- Рекурсивный поиск соответствующих текстовых аннотаций

**Обработка School Notebooks:**
- Чтение CSV с bbox-координатами отдельных слов
- Построчная сортировка: группировка по высоте (±100px), затем слева направо
- Конкатенация слов в полный текст c разворота тетради

**Объединение датасетов:**
- Загрузка обоих датасетов в единый формат `List[(image_path, ground_truth)]`
- Перемешивание с фиксированным seed для воспроизводимости
- Поддержка raw и preprocessed (аугментированных) версий

## 3. Метрики качества

### 3.1 Метрики точности

Класс `MetricsCalculator` реализует:

| Метрика | Описание | Формула |
|---------|----------|---------|
| **CER** | Character Error Rate | `edit_distance / len(reference) * 100` |
| **WER** | Word Error Rate | `word_edit_distance / len(words) * 100` |
| **Char Accuracy** | Точность на уровне символов | `(1 - CER/100) * 100` |
| **Word Accuracy** | Точность на уровне слов | `(1 - WER/100) * 100` |
| **Perfect Rate** | Доля идеально распознанных образцов | `count(CER=0) / total * 100` |

**Нормализация текста:**
- Приведение к нижнему регистру
- Удаление лишних пробелов
- Обеспечивает справедливое сравнение

**Детальный анализ ошибок:**
- Confusion matrix для замен символов
- Подсчет substitutions, deletions, insertions
- Топ-10 наиболее частых ошибок

### 3.2 Метрики производительности

Класс `PerformanceMetrics` измеряет:

**Латентность:**
- Warmup (3 итерации) - прогрев GPU и кэшей
- Измерение (10 итераций) - статистика времени выполнения
- Перцентили: P50, P95, P99

**Throughput:**
- Количество обрабатываемых образцов в секунду

**GPU Memory:**
- Потребление памяти GPU (allocated, max_allocated)

## 4. Результаты тестирования

### 4.1 Модель: trocr_cyrillic

**Конфигурация теста:**
- Датасет: Combined (HWR200 + School Notebooks)
- Preprocessed: Yes
- Образцов: 7

**Метрики точности:**
```
CER:           38.34% (±14.44%)
WER:           259.41% (±98.62%)
Char Accuracy: 61.66%
Perfect Rate:  0.00%
```

**Метрики производительности:**
```
Latency:    41.583 sec
P95:        56.062 sec
Throughput: 0.02 samples/sec
GPU Memory: 3923.47 MB
```

### 4.2 Интерпретация

**Точность:**
- CER 38% - неудовлетворительно (норма <5%)
- WER 259% - модель генерирует избыточный текст (галлюцинации)
- Perfect Rate 0% - ни один образец не распознан идеально

**Производительность:**
- Латентность ~42 сек/изображение - довольно медленно
- Throughput 0.02 samples/sec - также медленно

**Возможные причины:**
1. Модель использует двухэтапный подход (PaddleOCR детекция + TrOCR распознавание)
2. Слишком большой размер изображений

## 5. Технический стек

- **Python 3.12**
- **Libraries:** pandas, numpy, python-Levenshtein, PyTorch
- **OCR:** Transformers (TrOCR), PaddleOCR
- **Environment:** Google Colab (GPU T4)

## 6. Выводы

1. Разработан автоматизированный pipeline для валидации OCR моделей
2. Реализована гибкая система подготовки данных с поддержкой аугментаций
3. Выявлены проблемы качества тестируемой модели (CER 38%)
4. Система готова для тестрования других моделей и проведения сравнительного анализа
